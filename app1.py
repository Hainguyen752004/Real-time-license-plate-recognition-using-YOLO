import gradio as gr
import cv2
import os
import tempfile
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR

# Load models
plate_model = YOLO("models/license_plate_detector.pt")
vehicle_model = YOLO("models/yolov8n.pt")
ocr = PaddleOCR(use_angle_cls=False, lang_list=['en'], det=False, show_log=False)

def process_image(image):
    """X·ª≠ l√Ω ·∫£nh v√† hi·ªÉn th·ªã k·∫øt qu·∫£."""
    image = cv2.imread(image) if isinstance(image, str) else cv2.imdecode(np.frombuffer(image.read(), np.uint8), 1)
    
    # Nh·∫≠n di·ªán bi·ªÉn s·ªë
    plate_results = plate_model(image)
    for box in plate_results[0].boxes.xyxy.cpu().numpy():
        x1, y1, x2, y2 = map(int, box)
        plate_img = image[y1:y2, x1:x2]
        ocr_result = ocr.ocr(plate_img, cls=False)
        plate_text = " ".join(res[1][0] for res in ocr_result[0]) if ocr_result and len(ocr_result[0]) > 0 else ""
        if plate_text:
            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(image, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

    return image[:, :, ::-1]  # Chuy·ªÉn v·ªÅ RGB

def process_video(video_path):
    """X·ª≠ l√Ω video v√† tr·∫£ v·ªÅ video ƒë√£ x·ª≠ l√Ω."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return "Kh√¥ng th·ªÉ m·ªü video!", None

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    temp_output = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    output_path = temp_output.name
    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'X264'), fps, (frame_width, frame_height))

    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break

        vehicle_results = vehicle_model.track(frame, persist=True)
        plate_results = plate_model.track(frame, persist=True)

        if vehicle_results[0].boxes.id is not None:
            for box, cls, confidence in zip(
                vehicle_results[0].boxes.xyxy.cpu().numpy(),
                vehicle_results[0].boxes.cls.cpu().numpy().astype(int),
                vehicle_results[0].boxes.conf.cpu().numpy()
            ):
                if confidence < 0.8:
                    continue
                x1, y1, x2, y2 = map(int, box)
                class_name = vehicle_model.names[cls]
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

        if plate_results[0].boxes.id is not None:
            for box in plate_results[0].boxes.xyxy.cpu().numpy():
                x1, y1, x2, y2 = map(int, box)
                plate_img = frame[y1:y2, x1:x2]
                ocr_result = ocr.ocr(plate_img, cls=False)
                plate_text = " ".join(res[1][0] for res in ocr_result[0]) if ocr_result and len(ocr_result[0]) > 0 else ""
                if plate_text:
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                    cv2.putText(frame, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

        out.write(frame)

    cap.release()
    out.release()
    return "X·ª≠ l√Ω video ho√†n t·∫•t!", output_path

def handle_input(input_type, file):
    """X·ª≠ l√Ω input d·ª±a tr√™n lo·∫°i file (·∫£nh ho·∫∑c video)."""
    if input_type == "·∫¢nh":
        return process_image(file), None
    elif input_type == "Video":
        return None, process_video(file)
    return "Ch·ªçn ·∫£nh ho·∫∑c video!", None

# Giao di·ªán Gradio
with gr.Blocks() as demo:
    gr.Markdown("# üì∑ Nh·∫≠n di·ªán ph∆∞∆°ng ti·ªán & bi·ªÉn s·ªë xe üöó")

    input_type = gr.Radio(["·∫¢nh", "Video"], label="Ch·ªçn lo·∫°i d·ªØ li·ªáu")
    file_input = gr.File(label="T·∫£i l√™n ·∫£nh ho·∫∑c video")
    process_btn = gr.Button("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω")
    output_img = gr.Image(label="K·∫øt qu·∫£ ·∫£nh", visible=False)
    output_text = gr.Textbox(label="Tr·∫°ng th√°i")
    output_video = gr.Video(label="K·∫øt qu·∫£ video", visible=False)

    def process_all(input_type, file):
        img_result, vid_result = handle_input(input_type, file)
        return (
            img_result if img_result is not None else gr.update(visible=False),
            "X·ª≠ l√Ω ho√†n t·∫•t!" if vid_result else "Ch·ªçn ·∫£nh ho·∫∑c video!",
            vid_result if vid_result else gr.update(visible=False)
        )

    process_btn.click(process_all, inputs=[input_type, file_input], outputs=[output_img, output_text, output_video])

demo.launch()
