import streamlit as st
import cv2
import os
import tempfile
import numpy as np
import json
from ultralytics import YOLO
from paddleocr import PaddleOCR

# Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Load models
plate_model = YOLO("models/license_plate_detector.pt")
vehicle_model = YOLO("models/yolov8n.pt")
ocr = PaddleOCR(use_angle_cls=False, lang_list=['en'], det=False, show_log=False)

def process_image(image):
    """Xá»­ lÃ½ áº£nh vÃ  hiá»ƒn thá»‹ káº¿t quáº£."""
    image = cv2.imread(image) if isinstance(image, str) else cv2.imdecode(np.frombuffer(image.read(), np.uint8), 1)
    
    # Nháº­n diá»‡n biá»ƒn sá»‘
    plate_results = plate_model(image)
    detections = []
    
    for box in plate_results[0].boxes.xyxy.cpu().numpy():
        x1, y1, x2, y2 = map(int, box)
        plate_img = image[y1:y2, x1:x2]
        ocr_result = ocr.ocr(plate_img, cls=False)
        plate_text = " ".join(res[1][0] for res in ocr_result[0]) if ocr_result and len(ocr_result[0]) > 0 else ""
        
        if plate_text:
            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(image, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
            detections.append({"plate_text": plate_text, "coordinates": [x1, y1, x2, y2]})
    
    image_path = os.path.join(OUTPUT_DIR, "processed_image.jpg")
    cv2.imwrite(image_path, image)
    json_path = os.path.join(OUTPUT_DIR, "image_detections.json")
    with open(json_path, "w") as f:
        json.dump(detections, f, indent=4)
    
    return image[:, :, ::-1], image_path, json_path  # Chuyá»ƒn vá» RGB

def process_video(video_path):
    """Xá»­ lÃ½ video vÃ  lÆ°u file káº¿t quáº£."""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return "KhÃ´ng thá»ƒ má»Ÿ video!", None, None

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    output_video_path = os.path.join(OUTPUT_DIR, "processed_video.mp4")
    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'X264'), fps, (frame_width, frame_height))
    
    detections = []
    
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break

        vehicle_results = vehicle_model.track(frame, persist=True)
        plate_results = plate_model.track(frame, persist=True)

        if plate_results[0].boxes.id is not None:
            for box in plate_results[0].boxes.xyxy.cpu().numpy():
                x1, y1, x2, y2 = map(int, box)
                plate_img = frame[y1:y2, x1:x2]
                ocr_result = ocr.ocr(plate_img, cls=False)
                plate_text = " ".join(res[1][0] for res in ocr_result[0]) if ocr_result and len(ocr_result[0]) > 0 else ""
                
                if plate_text:
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                    cv2.putText(frame, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
                    detections.append({"plate_text": plate_text, "coordinates": [x1, y1, x2, y2]})
        
        out.write(frame)
    
    cap.release()
    out.release()
    
    json_path = os.path.join(OUTPUT_DIR, "video_detections.json")
    with open(json_path, "w") as f:
        json.dump(detections, f, indent=4)
    
    return "Xá»­ lÃ½ video hoÃ n táº¥t!", output_video_path, json_path

st.title("ğŸ“· Nháº­n diá»‡n phÆ°Æ¡ng tiá»‡n & biá»ƒn sá»‘ xe ğŸš—")
input_type = st.radio("Chá»n loáº¡i dá»¯ liá»‡u", ["áº¢nh", "Video"])
uploaded_file = st.file_uploader("Táº£i lÃªn áº£nh hoáº·c video")

if uploaded_file:
    if input_type == "áº¢nh":
        st.write("Äang xá»­ lÃ½ áº£nh...")
        image_result, image_path, json_path = process_image(uploaded_file)
        st.image(image_result, caption="áº¢nh Ä‘Ã£ xá»­ lÃ½", use_column_width=True)
        st.download_button("ğŸ“¥ Táº£i áº£nh xuá»‘ng", data=open(image_path, "rb").read(), file_name="processed_image.jpg", mime="image/jpeg")
        st.download_button("ğŸ“¥ Táº£i JSON xuá»‘ng", data=open(json_path, "rb").read(), file_name="image_detections.json", mime="application/json")
    
    elif input_type == "Video":
        st.write("Äang xá»­ lÃ½ video...")
        status, video_path, json_path = process_video(uploaded_file.name)
        st.success(status)
        st.video(video_path)
        st.download_button("ğŸ“¥ Táº£i video xuá»‘ng", data=open(video_path, "rb").read(), file_name="processed_video.mp4", mime="video/mp4")
        st.download_button("ğŸ“¥ Táº£i JSON xuá»‘ng", data=open(json_path, "rb").read(), file_name="video_detections.json", mime="application/json")
